model:
  device: 'cuda'
  batchsize: 1
  inference: True
preprocess:
  use_stopword: False

postprocess:

    
